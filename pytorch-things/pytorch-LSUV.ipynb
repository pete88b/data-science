{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Layerwise Sequential Unit Variance (LSUV)\n",
    "\n",
    "The goal of this notebook is to see if \"model specific weight initialization\" improves training a small neural net.\n",
    "\n",
    "See: All you need is a good init https://arxiv.org/abs/1511.06422\n",
    "\n",
    "Starting with pytorch-custom-layer.ipynb, we;\n",
    "- get rid of `NormalizeActivation`\n",
    "- \"borrow\" the hooks, LSUV approach etc from https://github.com/fastai/course-v3/blob/master/nbs/dl2/07a_lsuv.ipynb\n",
    "- make it easy to compare accuracy of a trained model with/without LSUV."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What does do_lsuv do?\n",
    "\n",
    "`do_lsuv` can make initialisation changes in reponse to the standard deviation (std) and mean of an activation\n",
    "\n",
    "### std\n",
    "- for each ReLU in the model\n",
    "    - run a batch of data through the model\n",
    "    - if the standard deviation of the activation of the ReLU is too far from 1, update the weights of the previous layer (conv or linear)\n",
    "    - repeat the previous 2 steps until std is close to 1\n",
    "    \n",
    "### mean\n",
    "- for each ReLU in the model\n",
    "    - run a batch of data through the model\n",
    "    - if the mean of the activation of the ReLU is too far from 0, update `ReLU#sub` (which makes a \"post-ReLU\" adjustment)\n",
    "    - repeat the previous 2 steps until mean is close to 0\n",
    "\n",
    "We try 3 variations around LSUV;\n",
    "- 1 std only - like https://arxiv.org/abs/1511.06422\n",
    "    - expect an initial mean of ~.5 because ReLU clamps to min zero\n",
    "- 2 mean then std - like https://github.com/fastai/course-v3/blob/master/nbs/dl2/07a_lsuv.ipynb\n",
    "    - expect an inital mean of ~.25 because the std adjustment messes up the mean adjustment we just made\n",
    "- 3 mean then std in a loop\n",
    "    - to get as close as possible to initial mean=0 and std=1\n",
    "\n",
    "Running this notebook should give results similar to;\n",
    "\n",
    "| LSUV type             |1st epoch accuracy |3rd epoch accuracy |\n",
    "|-----------------------|-------------------|-------------------|\n",
    "| mean then std in loop | ~93               | ~95               |\n",
    "| mean then std         | ~91               | ~95               |\n",
    "| std only              | ~89               | ~95               |\n",
    "| none                  | ~84               | ~92               |\n",
    "\n",
    "While all 3 LSUV variations end up with the same accuracy after 3 epochs (and have very similar stats after training too), \"mean then std in loop\" does consistently better on the 1st epoch.\n",
    "\n",
    "Interesting that `NormalizeActivation` gives better results (o:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from fastai.datasets import untar_data, URLs\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.MNIST)\n",
    "batch_size = 256\n",
    "device = 'cuda:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Pad(2), # pad images so we don't loose too much in the conv layers (28x28 to 32x32)\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize([0.1], [0.2752]) # see: calculate mean/standard deviation ...\n",
    "])\n",
    "def new_loader(type, shuffle):\n",
    "    return DataLoader(\n",
    "        ImageFolder(root=path/type, transform=transforms), \n",
    "        batch_size=batch_size, num_workers=1, shuffle=shuffle)\n",
    "train_loader = new_loader('training', True)\n",
    "test_loader = new_loader('testing', False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ReLU that can make a \"post-ReLU\" adjustment. When sub=0, this is just a normal ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLU(nn.Module):\n",
    "    def __init__(self, sub=0):\n",
    "        super(ReLU, self).__init__()\n",
    "        self.sub = sub\n",
    "     \n",
    "    def forward(self, x):\n",
    "        return F.relu(x).sub_(self.sub)\n",
    "    \n",
    "    def extra_repr(self):\n",
    "        return f'sub={self.sub}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(in_channels, out_channels, kernel_size):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_channels, out_channels, kernel_size),\n",
    "        ReLU(),\n",
    "        nn.MaxPool2d((2,2)))\n",
    "\n",
    "def fc_block(in_features, out_features):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(in_features, out_features),\n",
    "        ReLU())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all dimensions except the batch dimension torch.Size([16, 6, 6])\n",
      "fc1_in_features 576\n"
     ]
    }
   ],
   "source": [
    "# how many features input to 1st fully connected layer\n",
    "def num_flat_features(x): # taken from neural_networks_tutorial.html\n",
    "    size = x.size()[1:]\n",
    "    print('all dimensions except the batch dimension', size)\n",
    "    return torch.tensor(size).prod().item() # product of all elements in size\n",
    "conv_blocks = nn.Sequential(\n",
    "    conv_block(3, 6, 3),\n",
    "    conv_block(6, 16, 3))\n",
    "data, _ = next(iter(train_loader))\n",
    "fc1_in_features = num_flat_features(conv_blocks(data))\n",
    "print('fc1_in_features', fc1_in_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What does View do?\n",
    "\n",
    "View \"re-shapes\" the data going into the 1st fully connected layer. Having this logic in an nn.Module makes building the nn.Sequential easy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class View(nn.Module):\n",
    "    def forward(self, x): return x.view(-1, fc1_in_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search a model and return all ReLUs.\n",
    "\n",
    "When we find a ReLU we save the previous module (conv or linear) in `_previous` so that `do_lsuv` can easily update the weights of the previous module to affect std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_hookable_modules(net):\n",
    "    children = list(net.children())\n",
    "    if len(children) >= 2 and isinstance(children[0], (nn.Conv2d, nn.Linear)):\n",
    "        relu = children[1]\n",
    "        relu._previous = children[0] # need easy access to the previous layer\n",
    "        return [relu] # hook the ReLU after the Conv2d\n",
    "    return sum([find_hookable_modules(m) for m in net.children()], [])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"borrow\" hooks and `append_stat` from https://github.com/fastai/course-v3/blob/master/nbs/dl2/07a_lsuv.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Hook():\n",
    "    def __init__(self, module, f): \n",
    "        self.handle = module.register_forward_hook(partial(f, self))\n",
    "    def remove(self): \n",
    "        self.handle.remove()\n",
    "    def __del__(self): \n",
    "        self.remove()\n",
    "        \n",
    "class Hooks():\n",
    "    def __init__(self, modules, f): \n",
    "        self.hooks = [Hook(module, f) for module in modules]\n",
    "    def __enter__(self, *args):\n",
    "        return self.hooks\n",
    "    def __exit__ (self, *args): \n",
    "        self.remove()\n",
    "    def __del__(self): \n",
    "        self.remove()\n",
    "    def remove(self):\n",
    "        for hook in self.hooks: hook.remove()\n",
    "            \n",
    "def append_stat(hook, mod, inp, outp):\n",
    "    d = outp.data\n",
    "    hook.mean, hook.std = d.mean().item(), d.std().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(net):\n",
    "    net.eval()\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    incorrect = []\n",
    "    with torch.no_grad():\n",
    "        batch = 0\n",
    "        for (data, target) in test_loader:\n",
    "            batch += 1\n",
    "            target = target.to(device)\n",
    "            output = net(data.to(device))\n",
    "            predictions = torch.argmax(output, dim=1)\n",
    "            number_correct = (predictions == target).float().sum().item()\n",
    "            total += len(target)\n",
    "            correct += number_correct\n",
    "    print(f'accuracy over {total} test images: {round(correct/total*100, 2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, lrs):\n",
    "    def f(x): return round(x.item(), 4)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    epoch = 0\n",
    "    for lr in lrs:\n",
    "        net.train()\n",
    "        epoch += 1\n",
    "        optimizer = optim.SGD(net.parameters(), lr=lr)\n",
    "        losses = []\n",
    "        total = 0\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            total += len(data)\n",
    "            optimizer.zero_grad()\n",
    "            out = net(data.to(device))\n",
    "            loss = criterion(out, target.to(device))\n",
    "            if torch.isnan(loss):\n",
    "                raise RuntimeError('loss is nan: re-build net and re-try (maybe with lower lr)')\n",
    "            losses.append(loss.item())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        losses = torch.tensor(losses)\n",
    "        print('epoch', epoch, 'lr', lr, 'loss', f(losses[:25].mean()), 'last', f(loss), \n",
    "              'min', f(losses.min()), 'max', f(losses.max()), 'items', total)\n",
    "        accuracy(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab a batch of data for do_lsuv and print_stats\n",
    "xb, _ = next(iter(train_loader))\n",
    "xb = xb.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_lsuv(lsuv_type, net, module, tolerance=1e-3):\n",
    "    # lsuv_type: 1 std only, 2 mean then std, 3 mean then std in loop\n",
    "    hook = Hook(module, append_stat)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        if lsuv_type == 2:\n",
    "            while net(xb) is not None and abs(hook.mean) > tolerance: module.sub += hook.mean\n",
    "        if lsuv_type in [1, 2]:\n",
    "            while net(xb) is not None and abs(hook.std-1) > tolerance: module._previous.weight.data /= hook.std\n",
    "        else:\n",
    "            net(xb)\n",
    "            while abs(hook.mean) > tolerance or abs(hook.std-1) > tolerance:\n",
    "                module.sub += hook.mean\n",
    "                module._previous.weight.data /= hook.std\n",
    "                net(xb)\n",
    "        \n",
    "    hook.remove()\n",
    "    return 'LSUV type', lsuv_type, hook.mean, hook.std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use `print_stats` to check activation stats at the end of training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_stats(net):\n",
    "    with torch.no_grad():\n",
    "        with Hooks(find_hookable_modules(net), append_stat) as hooks:\n",
    "            net(xb)\n",
    "            for i, hook in enumerate(hooks):\n",
    "                print('layer', i, 'mean', hook.mean, 'std', hook.std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_and_train(lsuv_type):\n",
    "    net = nn.Sequential(\n",
    "        conv_block(3, 6, 3),\n",
    "        conv_block(6, 16, 3),\n",
    "        View(),\n",
    "        fc_block(fc1_in_features, 120),\n",
    "        fc_block(120, 84),\n",
    "        nn.Linear(84, 10)).to(device)\n",
    "    if lsuv_type: \n",
    "        for module in find_hookable_modules(net): \n",
    "            print(do_lsuv(lsuv_type, net, module))\n",
    "    print(net)\n",
    "    lrs = [1.5e-2, 1e-2, 5e-3] # 2.5e-2 can work for 1st epoch but can be too high - depending on init\n",
    "    train(net, lrs)\n",
    "    print_stats(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('LSUV type', 3, 0.00039939384441822767, 1.0000386238098145)\n",
      "('LSUV type', 3, 5.230880924500525e-05, 0.9999986290931702)\n",
      "('LSUV type', 3, 0.0001786887733032927, 1.0)\n",
      "('LSUV type', 3, -0.0006501650204882026, 0.9999986886978149)\n",
      "Sequential(\n",
      "  (0): Sequential(\n",
      "    (0): Conv2d(3, 6, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): ReLU(\n",
      "      sub=0.32031676825135946\n",
      "      (_previous): Conv2d(3, 6, kernel_size=(3, 3), stride=(1, 1))\n",
      "    )\n",
      "    (2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (1): Sequential(\n",
      "    (0): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): ReLU(\n",
      "      sub=0.4957392776850611\n",
      "      (_previous): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "    )\n",
      "    (2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (2): View()\n",
      "  (3): Sequential(\n",
      "    (0): Linear(in_features=576, out_features=120, bias=True)\n",
      "    (1): ReLU(\n",
      "      sub=0.6864708364009857\n",
      "      (_previous): Linear(in_features=576, out_features=120, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (4): Sequential(\n",
      "    (0): Linear(in_features=120, out_features=84, bias=True)\n",
      "    (1): ReLU(\n",
      "      sub=0.6238887012004852\n",
      "      (_previous): Linear(in_features=120, out_features=84, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (5): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n",
      "epoch 1 lr 0.015 loss 1.7693 last 0.1948 min 0.1711 max 2.4851 items 60000\n",
      "accuracy over 10000 test images: 93.03\n",
      "epoch 2 lr 0.01 loss 0.2247 last 0.2347 min 0.0814 max 0.3145 items 60000\n",
      "accuracy over 10000 test images: 94.04\n",
      "epoch 3 lr 0.005 loss 0.1689 last 0.1492 min 0.0788 max 0.2774 items 60000\n",
      "accuracy over 10000 test images: 95.81\n",
      "layer 0 mean 0.16951556503772736 std 1.8026633262634277\n",
      "layer 1 mean 0.8449780941009521 std 2.7897610664367676\n",
      "layer 2 mean 2.2314863204956055 std 3.743577003479004\n",
      "layer 3 mean 3.2304189205169678 std 4.707420825958252\n"
     ]
    }
   ],
   "source": [
    "setup_and_train(3) # run with LSUV mean then std in loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('LSUV type', 2, 0.2810233235359192, 0.9991238117218018)\n",
      "('LSUV type', 2, 0.2697175145149231, 0.9998458623886108)\n",
      "('LSUV type', 2, 0.2996945083141327, 0.9990943074226379)\n",
      "('LSUV type', 2, 0.4509803354740143, 0.999989926815033)\n",
      "Sequential(\n",
      "  (0): Sequential(\n",
      "    (0): Conv2d(3, 6, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): ReLU(\n",
      "      sub=0.12537558376789093\n",
      "      (_previous): Conv2d(3, 6, kernel_size=(3, 3), stride=(1, 1))\n",
      "    )\n",
      "    (2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (1): Sequential(\n",
      "    (0): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): ReLU(\n",
      "      sub=0.2298620641231537\n",
      "      (_previous): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "    )\n",
      "    (2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (2): View()\n",
      "  (3): Sequential(\n",
      "    (0): Linear(in_features=576, out_features=120, bias=True)\n",
      "    (1): ReLU(\n",
      "      sub=0.3807474374771118\n",
      "      (_previous): Linear(in_features=576, out_features=120, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (4): Sequential(\n",
      "    (0): Linear(in_features=120, out_features=84, bias=True)\n",
      "    (1): ReLU(\n",
      "      sub=0.2088669389486313\n",
      "      (_previous): Linear(in_features=120, out_features=84, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (5): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n",
      "epoch 1 lr 0.015 loss 1.7941 last 0.2426 min 0.1487 max 2.5774 items 60000\n",
      "accuracy over 10000 test images: 91.39\n",
      "epoch 2 lr 0.01 loss 0.223 last 0.2797 min 0.0911 max 0.3583 items 60000\n",
      "accuracy over 10000 test images: 95.12\n",
      "epoch 3 lr 0.005 loss 0.143 last 0.106 min 0.0659 max 0.2645 items 60000\n",
      "accuracy over 10000 test images: 95.77\n",
      "layer 0 mean 0.5214822888374329 std 1.7649394273757935\n",
      "layer 1 mean 1.0803875923156738 std 2.622337818145752\n",
      "layer 2 mean 2.494713544845581 std 3.658684015274048\n",
      "layer 3 mean 3.275887966156006 std 4.793938636779785\n"
     ]
    }
   ],
   "source": [
    "setup_and_train(2) # run with LSUV mean then std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('LSUV type', 1, 0.3195320963859558, 0.9998204708099365)\n",
      "('LSUV type', 1, 0.40966179966926575, 0.9998111724853516)\n",
      "('LSUV type', 1, 0.6362127065658569, 1.0006959438323975)\n",
      "('LSUV type', 1, 0.7175247073173523, 0.9999966025352478)\n",
      "Sequential(\n",
      "  (0): Sequential(\n",
      "    (0): Conv2d(3, 6, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): ReLU(\n",
      "      sub=0\n",
      "      (_previous): Conv2d(3, 6, kernel_size=(3, 3), stride=(1, 1))\n",
      "    )\n",
      "    (2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (1): Sequential(\n",
      "    (0): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): ReLU(\n",
      "      sub=0\n",
      "      (_previous): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "    )\n",
      "    (2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (2): View()\n",
      "  (3): Sequential(\n",
      "    (0): Linear(in_features=576, out_features=120, bias=True)\n",
      "    (1): ReLU(\n",
      "      sub=0\n",
      "      (_previous): Linear(in_features=576, out_features=120, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (4): Sequential(\n",
      "    (0): Linear(in_features=120, out_features=84, bias=True)\n",
      "    (1): ReLU(\n",
      "      sub=0\n",
      "      (_previous): Linear(in_features=120, out_features=84, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (5): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n",
      "epoch 1 lr 0.015 loss 1.726 last 0.278 min 0.1702 max 2.3797 items 60000\n",
      "accuracy over 10000 test images: 89.44\n",
      "epoch 2 lr 0.01 loss 0.2358 last 0.0761 min 0.0761 max 0.3561 items 60000\n",
      "accuracy over 10000 test images: 94.71\n",
      "epoch 3 lr 0.005 loss 0.1514 last 0.067 min 0.067 max 0.2464 items 60000\n",
      "accuracy over 10000 test images: 95.75\n",
      "layer 0 mean 0.6276647448539734 std 1.9397250413894653\n",
      "layer 1 mean 1.3751722574234009 std 3.217329740524292\n",
      "layer 2 mean 2.959056854248047 std 4.073469638824463\n",
      "layer 3 mean 3.5941555500030518 std 4.164583683013916\n"
     ]
    }
   ],
   "source": [
    "setup_and_train(1) # run with LSUV std only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Sequential(\n",
      "    (0): Conv2d(3, 6, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): ReLU(sub=0)\n",
      "    (2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (1): Sequential(\n",
      "    (0): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): ReLU(sub=0)\n",
      "    (2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (2): View()\n",
      "  (3): Sequential(\n",
      "    (0): Linear(in_features=576, out_features=120, bias=True)\n",
      "    (1): ReLU(sub=0)\n",
      "  )\n",
      "  (4): Sequential(\n",
      "    (0): Linear(in_features=120, out_features=84, bias=True)\n",
      "    (1): ReLU(sub=0)\n",
      "  )\n",
      "  (5): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n",
      "epoch 1 lr 0.015 loss 2.2933 last 0.3849 min 0.3849 max 2.3155 items 60000\n",
      "accuracy over 10000 test images: 84.36\n",
      "epoch 2 lr 0.01 loss 0.4391 last 0.3158 min 0.2247 max 0.572 items 60000\n",
      "accuracy over 10000 test images: 90.4\n",
      "epoch 3 lr 0.005 loss 0.3011 last 0.467 min 0.1641 max 0.467 items 60000\n",
      "accuracy over 10000 test images: 92.11\n",
      "layer 0 mean 0.6760203242301941 std 2.2174859046936035\n",
      "layer 1 mean 2.2534029483795166 std 4.894435882568359\n",
      "layer 2 mean 3.576188325881958 std 4.48058557510376\n",
      "layer 3 mean 2.4904844760894775 std 2.9664883613586426\n"
     ]
    }
   ],
   "source": [
    "setup_and_train(0) # run without LSUV"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
