{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a custom nn.Module\n",
    "\n",
    "The goal of this notebook is to show how we can create a custom nn.Module that performs some kind of calculation as part of a neural net.\n",
    "\n",
    "Starting with https://pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html, we;\n",
    "- use the fastai MNIST dataset\n",
    "- update to use 3 chanel input (i.e. pass 3 rather than 1 to the 1st `Conv2d`)\n",
    "- refactor to use `nn.Sequential`\n",
    "- create custom modules; `NormalizeActivation` and `View`\n",
    "- make it easy to compare accuracy of a trained model with/without normalize activation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What does the NormalizeActivation layer do?\n",
    "\n",
    "- Before starting training, each NormalizeActivation layer can learn the mean and standard deviation of its input. See: `learn_normalize_activation_stats`.\n",
    "- During training, each NormalizeActivation layer can \"normalize\" its input using the learned mean and standard deviation - so that the input to the next layer has a mean of zero and a standard deviation of 1.\n",
    "\n",
    "Running this notebook should give results similar to;\n",
    "\n",
    "|                                                   |accuracy |\n",
    "|---------------------------------------------------|---------|\n",
    "| with normalize activation - setup_and_train(True) | ~98     |\n",
    "| no normalize activation - setup_and_train(False)  | ~92     |\n",
    "\n",
    "While it is interesting that normalizing activation layers improves accuracy in this simple example, there are lots of other techniques (batch norm, model specific weight initialization ...) that should give better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from fastai.datasets import untar_data, URLs\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.MNIST)\n",
    "batch_size = 256\n",
    "device = 'cuda:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Pad(2), # pad images so we don't loose too much in the conv layers (28x28 to 32x32)\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize([0.1], [0.2752]) # see: calculate mean/standard deviation ...\n",
    "])\n",
    "def new_loader(type, shuffle):\n",
    "    return DataLoader(\n",
    "        ImageFolder(root=path/type, transform=transforms), \n",
    "        batch_size=batch_size, num_workers=1, shuffle=shuffle)\n",
    "train_loader = new_loader('training', True)\n",
    "test_loader = new_loader('testing', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NormalizeActivation(nn.Module):\n",
    "    count = 0\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(NormalizeActivation, self).__init__()\n",
    "        self.mode = 0 # 0=do nothing, 1=learning, 2=active\n",
    "        self.id = NormalizeActivation.count\n",
    "        NormalizeActivation.count += 1\n",
    "        \n",
    "    def start_learning(self):\n",
    "        self.running_n = 0\n",
    "        self.running_sum = 0.\n",
    "        self.running_sum_of_squares = 0.\n",
    "        self.mode = 1\n",
    "        \n",
    "    def stop_learning(self):\n",
    "        self.mean = self.running_sum / self.running_n\n",
    "        self.var = self.running_sum_of_squares / self.running_n - self.mean.pow(2)\n",
    "        self.std = self.var.sqrt()\n",
    "        print('NormalizeActivation#stop_learning', self.id, self.mean, self.std)\n",
    "        self.mode = 2\n",
    "    \n",
    "    def forward(self, x):\n",
    "        if self.mode == 1:\n",
    "            self.running_n += x.numel()\n",
    "            self.running_sum += x.sum()\n",
    "            self.running_sum_of_squares += x.pow(2).sum()\n",
    "        if self.mode == 2:\n",
    "            x = (x - self.mean) / self.std\n",
    "        return x\n",
    "    \n",
    "    def extra_repr(self):\n",
    "        mean = getattr(self, 'mean', None)\n",
    "        std = getattr(self, 'std', None)\n",
    "        return f'id={self.id} mode={self.mode} mean={mean} std={std}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(in_channels, out_channels, kernel_size):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_channels, out_channels, kernel_size),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d((2,2)),\n",
    "        NormalizeActivation())\n",
    "\n",
    "def fc_block(in_features, out_features):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(in_features, out_features),\n",
    "        nn.ReLU(),\n",
    "        NormalizeActivation())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many features input to 1st fully connected layer\n",
    "fc1_in_features = 576 # see: finding fc1_in_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What does View do?\n",
    "\n",
    "View \"re-shapes\" the data going into the 1st fully connected layer. Having this logic in an nn.Module makes building the nn.Sequential easy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class View(nn.Module):\n",
    "    def forward(self, x): return x.view(-1, fc1_in_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn_normalize_activation_stats(net, batches_per_module=10):\n",
    "    normalize_activation_modules = [\n",
    "        m for _, m in net.named_modules() if isinstance(m, NormalizeActivation)]\n",
    "    idx = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            if batch_idx % batches_per_module == 0:\n",
    "                if idx > 0: \n",
    "                    normalize_activation_modules[idx-1].stop_learning()\n",
    "                if idx < len(normalize_activation_modules): \n",
    "                    normalize_activation_modules[idx].start_learning()\n",
    "                else: \n",
    "                    break\n",
    "                idx += 1\n",
    "            out = net(data.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(net):\n",
    "    net.eval()\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    incorrect = []\n",
    "    with torch.no_grad():\n",
    "        batch = 0\n",
    "        for (data, target) in test_loader:\n",
    "            batch += 1\n",
    "            target = target.to(device)\n",
    "            output = net(data.to(device))\n",
    "            predictions = torch.argmax(output, dim=1)\n",
    "            number_correct = (predictions == target).float().sum().item()\n",
    "            total += len(target)\n",
    "            correct += number_correct\n",
    "    print(f'accuracy over {total} test images: {round(correct/total*100, 2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, lrs):\n",
    "    def f(x): return round(x.item(), 4)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    epoch = 0\n",
    "    for lr in lrs:\n",
    "        net.train()\n",
    "        epoch += 1\n",
    "        optimizer = optim.SGD(net.parameters(), lr=lr)\n",
    "        losses = []\n",
    "        total = 0\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            total += len(data)\n",
    "            optimizer.zero_grad()\n",
    "            out = net(data.to(device))\n",
    "            loss = criterion(out, target.to(device))\n",
    "            if torch.isnan(loss):\n",
    "                raise RuntimeError('loss is nan: re-build net and re-try (maybe with lower lr)')\n",
    "            losses.append(loss.item())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        losses = torch.tensor(losses)\n",
    "        print('epoch', epoch, 'lr', lr, 'loss', f(losses[:25].mean()), 'last', f(loss), \n",
    "              'min', f(losses.min()), 'max', f(losses.max()), 'items', total)\n",
    "        accuracy(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_and_train(use_normalize_activation):\n",
    "    net = nn.Sequential(\n",
    "        conv_block(3, 6, 3),\n",
    "        conv_block(6, 16, 3),\n",
    "        View(),\n",
    "        fc_block(fc1_in_features, 120),\n",
    "        fc_block(120, 84),\n",
    "        nn.Linear(84, 10)).to(device)\n",
    "    if use_normalize_activation: \n",
    "        learn_normalize_activation_stats(net)\n",
    "    print(net)\n",
    "    lrs = [1.5e-2, 1e-2, 5e-3] # 2.5e-2 can work for 1st epoch but can be too high - depending on init\n",
    "    train(net, lrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NormalizeActivation#stop_learning 0 tensor(0.2739, device='cuda:0') tensor(0.4720, device='cuda:0')\n",
      "NormalizeActivation#stop_learning 1 tensor(0.3880, device='cuda:0') tensor(0.5016, device='cuda:0')\n",
      "NormalizeActivation#stop_learning 2 tensor(0.2628, device='cuda:0') tensor(0.3556, device='cuda:0')\n",
      "NormalizeActivation#stop_learning 3 tensor(0.2519, device='cuda:0') tensor(0.3518, device='cuda:0')\n",
      "Sequential(\n",
      "  (0): Sequential(\n",
      "    (0): Conv2d(3, 6, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): NormalizeActivation(id=0 mode=2 mean=0.273936003446579 std=0.4720093607902527)\n",
      "  )\n",
      "  (1): Sequential(\n",
      "    (0): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): NormalizeActivation(id=1 mode=2 mean=0.3879949748516083 std=0.5016279220581055)\n",
      "  )\n",
      "  (2): View()\n",
      "  (3): Sequential(\n",
      "    (0): Linear(in_features=576, out_features=120, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): NormalizeActivation(id=2 mode=2 mean=0.26283779740333557 std=0.3556366562843323)\n",
      "  )\n",
      "  (4): Sequential(\n",
      "    (0): Linear(in_features=120, out_features=84, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): NormalizeActivation(id=3 mode=2 mean=0.2519252300262451 std=0.35180389881134033)\n",
      "  )\n",
      "  (5): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n",
      "epoch 1 lr 0.015 loss 1.0422 last 0.1875 min 0.0526 max 2.4648 items 60000\n",
      "accuracy over 10000 test images: 96.68\n",
      "epoch 2 lr 0.01 loss 0.0934 last 0.2344 min 0.0295 max 0.2344 items 60000\n",
      "accuracy over 10000 test images: 97.58\n",
      "epoch 3 lr 0.005 loss 0.0589 last 0.0372 min 0.0139 max 0.1675 items 60000\n",
      "accuracy over 10000 test images: 98.12\n"
     ]
    }
   ],
   "source": [
    "setup_and_train(True) # run with NormalizeActivation enabled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Sequential(\n",
      "    (0): Conv2d(3, 6, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): NormalizeActivation(id=4 mode=0 mean=None std=None)\n",
      "  )\n",
      "  (1): Sequential(\n",
      "    (0): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): NormalizeActivation(id=5 mode=0 mean=None std=None)\n",
      "  )\n",
      "  (2): View()\n",
      "  (3): Sequential(\n",
      "    (0): Linear(in_features=576, out_features=120, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): NormalizeActivation(id=6 mode=0 mean=None std=None)\n",
      "  )\n",
      "  (4): Sequential(\n",
      "    (0): Linear(in_features=120, out_features=84, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): NormalizeActivation(id=7 mode=0 mean=None std=None)\n",
      "  )\n",
      "  (5): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n",
      "epoch 1 lr 0.015 loss 2.2918 last 0.5884 min 0.4263 max 2.3032 items 60000\n",
      "accuracy over 10000 test images: 81.71\n",
      "epoch 2 lr 0.01 loss 0.4491 last 0.4014 min 0.2187 max 0.5742 items 60000\n",
      "accuracy over 10000 test images: 86.8\n",
      "epoch 3 lr 0.005 loss 0.3017 last 0.2926 min 0.1613 max 0.4577 items 60000\n",
      "accuracy over 10000 test images: 92.65\n"
     ]
    }
   ],
   "source": [
    "setup_and_train(False) # run without NormalizeActivation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate mean/standard deviation on the training data\n",
    "\n",
    "We need to calculate stats on the data coming out of the train loader rather than the unmodified input data. i.e. padding changes stats from ([0.131], [0.308]) to ([0.1], [0.2752]).\n",
    "\n",
    "Note: the calc_and_print_stats() call is commented as it takes a while to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: use NormalizeActivation to calc mean/std over batches\n",
    "def calc_and_print_stats():\n",
    "    # do all transforms except normalize\n",
    "    transforms = torchvision.transforms.Compose([\n",
    "        torchvision.transforms.Pad(2),\n",
    "        torchvision.transforms.ToTensor()])\n",
    "    loader = DataLoader(\n",
    "        ImageFolder(root=path/'training', transform=transforms), batch_size=batch_size)\n",
    "    running_n, running_sum, running_sum_of_squares = 0, 0., 0.\n",
    "    for (x, _) in loader: # x.shape [bs, 3, 32, 32]\n",
    "        running_n += x.numel() / 3\n",
    "        running_sum += x.sum((0, 2, 3), keepdim=True)\n",
    "        running_sum_of_squares += x.pow(2).sum((0, 2, 3), keepdim=True)\n",
    "    mean = running_sum / running_n\n",
    "    variance = running_sum_of_squares / running_n - mean.pow(2)\n",
    "    standard_deviation = variance.sqrt()\n",
    "    print('mean', mean.view([3,]), \n",
    "          'standard_deviation', standard_deviation.view([3,]), \n",
    "          'variance', variance.view([3,]))\n",
    "        \n",
    "# calc_and_print_stats()\n",
    "# uncomment the line above and you'll get this output;\n",
    "# mean tensor([0.1000, 0.1000, 0.1000]) \n",
    "# standard_deviation tensor([0.2752, 0.2752, 0.2752]) \n",
    "# variance tensor([0.0757, 0.0757, 0.0757])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding fc1_in_features\n",
    "\n",
    "To find the number of features that will go into the 1st fully connected layer, we need to know the shape of the output of the conv layers.\n",
    "We can;\n",
    "- create a \"net\" with just the conv blocks\n",
    "- pass one batch of data through this \"net\"\n",
    "- pass the output of this \"net\" to num_flat_features\n",
    "\n",
    "There are probably ways to calculate this, but ... for me, it's interesting that we can create part of a neural net and take a look at its output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all dimensions except the batch dimension torch.Size([16, 6, 6])\n",
      "fc1_in_features 576\n"
     ]
    }
   ],
   "source": [
    "def num_flat_features(x): # taken from neural_networks_tutorial.html\n",
    "    size = x.size()[1:]\n",
    "    print('all dimensions except the batch dimension', size)\n",
    "    num_features = 1\n",
    "    for s in size:\n",
    "        num_features *= s\n",
    "    return num_features\n",
    "conv_blocks = nn.Sequential(\n",
    "    conv_block(3, 6, 3),\n",
    "    conv_block(6, 16, 3))\n",
    "data, _ = next(iter(train_loader))\n",
    "print('fc1_in_features', num_flat_features(conv_blocks(data)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
