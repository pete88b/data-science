{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a custom nn.Module\n",
    "\n",
    "The goal of this notebook is to show how we can create a custom nn.Module that performs some kind of calculation as part of a neural net.\n",
    "\n",
    "Starting with https://pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html, we;\n",
    "- use the fastai MNIST dataset\n",
    "- update to use 3 chanel input (i.e. pass 3 rather than 1 to the 1st `Conv2d`)\n",
    "- refactor to use `nn.Sequential`\n",
    "- create custom modules; `NormalizeActivation` and `View`\n",
    "- make it easy to compare accuracy of a trained model with/without normalize activation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What does the NormalizeActivation layer do?\n",
    "\n",
    "- Before starting training, each NormalizeActivation layer can learn the mean and standard deviation of its input. See: `learn_normalize_activation_stats`.\n",
    "- During training, each NormalizeActivation layer can \"normalize\" its input using the learned mean and standard deviation - so that the input to the next layer has a mean of zero and a standard deviation of 1.\n",
    "\n",
    "Running this notebook should give results similar to;\n",
    "\n",
    "|                                                   |accuracy |\n",
    "|---------------------------------------------------|---------|\n",
    "| with normalize activation - setup_and_train(True) | ~98     |\n",
    "| no normalize activation - setup_and_train(False)  | ~92     |\n",
    "\n",
    "While it is interesting that normalizing activation layers improves accuracy in this simple example, there are lots of other techniques (batch norm, model specific weight initialization ...) that should give better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from fastai.datasets import untar_data, URLs\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.MNIST)\n",
    "batch_size = 256\n",
    "device = 'cuda:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Pad(2), # pad images so we don't loose too much in the conv layers (28x28 to 32x32)\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize([0.1], [0.2752]) # see: calculate mean/standard deviation ...\n",
    "])\n",
    "def new_loader(type, shuffle):\n",
    "    return DataLoader(\n",
    "        ImageFolder(root=path/type, transform=transforms), \n",
    "        batch_size=batch_size, num_workers=1, shuffle=shuffle)\n",
    "train_loader = new_loader('training', True)\n",
    "test_loader = new_loader('testing', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NormalizeActivation(nn.Module):\n",
    "    count = 0\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(NormalizeActivation, self).__init__()\n",
    "        self.mode = 0 # 0=do nothing, 1=learning, 2=active\n",
    "        self.id = NormalizeActivation.count\n",
    "        NormalizeActivation.count += 1\n",
    "        \n",
    "    def start_learning(self):\n",
    "        self.mean_list = torch.tensor([]).to(device)\n",
    "        self.std_list = torch.tensor([]).to(device)\n",
    "        self.mode = 1\n",
    "        \n",
    "    def stop_learning(self):\n",
    "        self.mean = self.mean_list.mean()\n",
    "        self.std = self.std_list.mean()\n",
    "        self.mean_list = None\n",
    "        self.std_list = None\n",
    "        print('NormalizeActivation#stop_learning', self.id, self.mean, self.std)\n",
    "        self.mode = 2\n",
    "    \n",
    "    def forward(self, x):\n",
    "        if self.mode == 1:\n",
    "            self.mean_list = torch.cat((self.mean_list, x.mean()[None]), 0)\n",
    "            self.std_list = torch.cat((self.std_list, x.std()[None]), 0)\n",
    "        if self.mode == 2:\n",
    "            x = (x - self.mean) / self.std\n",
    "        return x\n",
    "    \n",
    "    def extra_repr(self):\n",
    "        mean = getattr(self, 'mean', None)\n",
    "        std = getattr(self, 'std', None)\n",
    "        return f'id={self.id} mode={self.mode} mean={mean} std={std}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(in_channels, out_channels, kernel_size):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_channels, out_channels, kernel_size),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d((2,2)),\n",
    "        NormalizeActivation())\n",
    "\n",
    "def fc_block(in_features, out_features):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(in_features, out_features),\n",
    "        nn.ReLU(),\n",
    "        NormalizeActivation())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many features input to 1st fully connected layer\n",
    "fc1_in_features = 576 # see: finding fc1_in_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What does View do?\n",
    "\n",
    "View \"re-shapes\" the data going into the 1st fully connected layer. Having this logic in an nn.Module makes building the nn.Sequential easy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class View(nn.Module):\n",
    "    def forward(self, x): return x.view(-1, fc1_in_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn_normalize_activation_stats(net, batches_per_module=10):\n",
    "    normalize_activation_modules = [\n",
    "        m for _, m in net.named_modules() if isinstance(m, NormalizeActivation)]\n",
    "    idx = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            if batch_idx % batches_per_module == 0:\n",
    "                if idx > 0: \n",
    "                    normalize_activation_modules[idx-1].stop_learning()\n",
    "                if idx < len(normalize_activation_modules): \n",
    "                    normalize_activation_modules[idx].start_learning()\n",
    "                else: \n",
    "                    break\n",
    "                idx += 1\n",
    "            out = net(data.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(net):\n",
    "    net.eval()\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    incorrect = []\n",
    "    with torch.no_grad():\n",
    "        batch = 0\n",
    "        for (data, target) in test_loader:\n",
    "            batch += 1\n",
    "            target = target.to(device)\n",
    "            output = net(data.to(device))\n",
    "            predictions = torch.argmax(output, dim=1)\n",
    "            number_correct = (predictions == target).float().sum().item()\n",
    "            total += len(target)\n",
    "            correct += number_correct\n",
    "    print(f'accuracy over {total} test images: {round(correct/total*100, 2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, lrs):\n",
    "    def f(x): return round(x.item(), 4)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    epoch = 0\n",
    "    for lr in lrs:\n",
    "        net.train()\n",
    "        epoch += 1\n",
    "        optimizer = optim.SGD(net.parameters(), lr=lr)\n",
    "        losses = []\n",
    "        total = 0\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            total += len(data)\n",
    "            optimizer.zero_grad()\n",
    "            out = net(data.to(device))\n",
    "            loss = criterion(out, target.to(device))\n",
    "            if torch.isnan(loss):\n",
    "                raise RuntimeError('loss is nan: re-build net and re-try (maybe with lower lr)')\n",
    "            losses.append(loss.item())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        losses = torch.tensor(losses)\n",
    "        print('epoch', epoch, 'lr', lr, 'loss', f(losses[:25].mean()), 'last', f(loss), \n",
    "              'min', f(losses.min()), 'max', f(losses.max()), 'items', total)\n",
    "        accuracy(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_and_train(use_normalize_activation):\n",
    "    net = nn.Sequential(\n",
    "        conv_block(3, 6, 3),\n",
    "        conv_block(6, 16, 3),\n",
    "        View(),\n",
    "        fc_block(fc1_in_features, 120),\n",
    "        fc_block(120, 84),\n",
    "        nn.Linear(84, 10)).to(device)\n",
    "    if use_normalize_activation: \n",
    "        learn_normalize_activation_stats(net)\n",
    "    print(net)\n",
    "    lrs = [1.5e-2, 1e-2, 5e-3] # 2.5e-2 can work for 1st epoch but can be too high - depending on init\n",
    "    train(net, lrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NormalizeActivation#stop_learning 0 tensor(0.2082, device='cuda:0') tensor(0.3664, device='cuda:0')\n",
      "NormalizeActivation#stop_learning 1 tensor(0.5126, device='cuda:0') tensor(0.6389, device='cuda:0')\n",
      "NormalizeActivation#stop_learning 2 tensor(0.2028, device='cuda:0') tensor(0.3290, device='cuda:0')\n",
      "NormalizeActivation#stop_learning 3 tensor(0.2072, device='cuda:0') tensor(0.3128, device='cuda:0')\n",
      "Sequential(\n",
      "  (0): Sequential(\n",
      "    (0): Conv2d(3, 6, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): NormalizeActivation(id=0 mode=2 mean=0.20817556977272034 std=0.3663758933544159)\n",
      "  )\n",
      "  (1): Sequential(\n",
      "    (0): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): NormalizeActivation(id=1 mode=2 mean=0.512565553188324 std=0.6388803720474243)\n",
      "  )\n",
      "  (2): View()\n",
      "  (3): Sequential(\n",
      "    (0): Linear(in_features=576, out_features=120, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): NormalizeActivation(id=2 mode=2 mean=0.20277462899684906 std=0.3289963901042938)\n",
      "  )\n",
      "  (4): Sequential(\n",
      "    (0): Linear(in_features=120, out_features=84, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): NormalizeActivation(id=3 mode=2 mean=0.2071639597415924 std=0.3128037452697754)\n",
      "  )\n",
      "  (5): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n",
      "epoch 1 lr 0.015 loss 1.0947 last 0.0842 min 0.0448 max 2.4413 items 60000\n",
      "accuracy over 10000 test images: 95.98\n",
      "epoch 2 lr 0.01 loss 0.0961 last 0.0657 min 0.0265 max 0.1739 items 60000\n",
      "accuracy over 10000 test images: 97.53\n",
      "epoch 3 lr 0.005 loss 0.0697 last 0.061 min 0.0207 max 0.1869 items 60000\n",
      "accuracy over 10000 test images: 98.04\n"
     ]
    }
   ],
   "source": [
    "setup_and_train(True) # run with NormalizeActivation enabled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Sequential(\n",
      "    (0): Conv2d(3, 6, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): NormalizeActivation(id=4 mode=0 mean=None std=None)\n",
      "  )\n",
      "  (1): Sequential(\n",
      "    (0): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): NormalizeActivation(id=5 mode=0 mean=None std=None)\n",
      "  )\n",
      "  (2): View()\n",
      "  (3): Sequential(\n",
      "    (0): Linear(in_features=576, out_features=120, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): NormalizeActivation(id=6 mode=0 mean=None std=None)\n",
      "  )\n",
      "  (4): Sequential(\n",
      "    (0): Linear(in_features=120, out_features=84, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): NormalizeActivation(id=7 mode=0 mean=None std=None)\n",
      "  )\n",
      "  (5): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n",
      "epoch 1 lr 0.015 loss 2.3013 last 0.8092 min 0.6967 max 2.3111 items 60000\n",
      "accuracy over 10000 test images: 77.82\n",
      "epoch 2 lr 0.01 loss 0.6045 last 0.317 min 0.2799 max 0.7552 items 60000\n",
      "accuracy over 10000 test images: 84.98\n",
      "epoch 3 lr 0.005 loss 0.3412 last 0.2824 min 0.1761 max 0.4951 items 60000\n",
      "accuracy over 10000 test images: 91.82\n"
     ]
    }
   ],
   "source": [
    "setup_and_train(False) # run without NormalizeActivation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate mean/standard deviation on the training data\n",
    "\n",
    "We need to calculate stats on the data coming out of the train loader rather than the unmodified input data. i.e. padding changes stats from ([0.131], [0.308]) to ([0.1], [0.2752]).\n",
    "\n",
    "Note: StatsHelper().gather_and_print() is commented as it takes a while to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StatsHelper:\n",
    "    def __init__(self):\n",
    "        # do all transforms except normalize\n",
    "        transforms = torchvision.transforms.Compose([\n",
    "            torchvision.transforms.Pad(2),\n",
    "            torchvision.transforms.ToTensor()])\n",
    "        self.loader = DataLoader(\n",
    "            ImageFolder(root=path/'training', transform=transforms), batch_size=batch_size)\n",
    "    def print_stats(self, a_list):\n",
    "        print('mean', a_list.mean(), 'min', a_list.min(), 'max', a_list.max())\n",
    "    def gather_and_print(self):\n",
    "        self.mean_list = torch.tensor([])\n",
    "        self.std_list = torch.tensor([])\n",
    "        for (x, _) in self.loader:\n",
    "            x.to(device)\n",
    "            self.mean_list = torch.cat((self.mean_list, x[:,0].mean()[None]), 0)\n",
    "            self.std_list = torch.cat((self.std_list, x[:,0].std()[None]), 0)\n",
    "        self.print_stats(self.mean_list)\n",
    "        self.print_stats(self.std_list)\n",
    "# StatsHelper().gather_and_print()\n",
    "# uncomment the line above and you'll get this output;\n",
    "# mean tensor(0.1000) min tensor(0.0944) max tensor(0.1066)\n",
    "# mean tensor(0.2752) min tensor(0.2673) max tensor(0.2837)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding fc1_in_features\n",
    "\n",
    "To find the number of features that will go into the 1st fully connected layer, we need to know the shape of the output of the conv layers.\n",
    "We can;\n",
    "- create a \"net\" with just the conv blocks\n",
    "- pass one batch of data through this \"net\"\n",
    "- pass the output of this \"net\" to num_flat_features\n",
    "\n",
    "There are probably ways to calculate this, but ... for me, it's interesting that we can create part of a neural net and take a look at its output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all dimensions except the batch dimension torch.Size([16, 6, 6])\n",
      "fc1_in_features 576\n"
     ]
    }
   ],
   "source": [
    "def num_flat_features(x): # taken from neural_networks_tutorial.html\n",
    "    size = x.size()[1:]\n",
    "    print('all dimensions except the batch dimension', size)\n",
    "    num_features = 1\n",
    "    for s in size:\n",
    "        num_features *= s\n",
    "    return num_features\n",
    "conv_blocks = nn.Sequential(\n",
    "    conv_block(3, 6, 3),\n",
    "    conv_block(6, 16, 3))\n",
    "data, _ = next(iter(train_loader))\n",
    "print('fc1_in_features', num_flat_features(conv_blocks(data)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
