{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook uses images create via the web app\n",
    "\n",
    "Please see: data-science/myohddac/README.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/peter/github/data-science/myohddac/notebooks')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = Path.cwd();path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the MNIST classifier: learner and databunch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = load_learner(path, 'mnist-learn-export.pkl')\n",
    "data = DataBunch.load_empty(path, 'mnist-data-export.pkl')\n",
    "image_list = ImageList.from_folder(path.parents[0]/'images')\n",
    "data.add_test(image_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the \"MNIST or not\" model - we'll use the same data for both models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_or_not_learn = load_learner(path, 'mnist-or-not-learn-export.pkl')\n",
    "opt_thresh = mnist_or_not_learn.model.opt_thresh\n",
    "# mnist_or_not_data = DataBunch.load_empty(path, 'mnist-or-not-data-export.pkl')\n",
    "# mnist_or_not_data.add_test(image_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run an image through both models\n",
    "- the MNIST classifier seems to be doing a good job\n",
    "- the \"MNIST or not\" model is not doing so well - maybe the threshold is too high for these images?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/peter/github/data-science/myohddac/images/4-y-1576168454.594822.png\n",
      "target 4 predicted 4 with \"probability\" 0.993\n",
      "is_digit_score 0.737 is above the threshold of 0.504\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_item_idx = 3\n",
    "print(image_list.items[data_item_idx])\n",
    "img_size = 4\n",
    "img = data.test_ds[data_item_idx][0]\n",
    "img.show(figsize=(img_size, img_size), title='processed image')\n",
    "image_list[data_item_idx].show(\n",
    "    figsize=(img_size, img_size), title='original image')\n",
    "target = image_list.items[data_item_idx].stem[0]\n",
    "pred = learn.predict(img)\n",
    "prob = round(torch.max(pred[2]).item(), 3)\n",
    "is_digit_score = round(mnist_or_not_learn.predict(img)[1].item(), 3)\n",
    "is_digit = is_digit_score>opt_thresh\n",
    "print('target', target, 'predicted', pred[0], 'with \"probability\"', prob)\n",
    "print('is_digit_score', is_digit_score, 'is', 'above' if is_digit else 'below', 'the threshold of', opt_thresh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How can we use these models to confidently classify hand drawn digits, that might not be digits?\n",
    "\n",
    "We have;\n",
    "- a classifier that will always tell us the image is a digit and\n",
    "- a regressor that will tell us how much digit is in the image\n",
    "\n",
    "Maybe it's a simple as saying; if both scores are high, we can be confident in the classification?\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td rowspan=4 style='transform: rotate(-90deg)' valign=\"bottom\">Regressor</td>\n",
    "        <td colspan=3>Classifier</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td></td><td>high</td><td>low</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>high</td><td bgcolor='green'>Y</td><td bgcolor='orange'>?</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>low</td><td bgcolor='orange'>?</td><td bgcolor='red'>N</td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "TODO: try to find thresh values, which could be different for different digits"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
