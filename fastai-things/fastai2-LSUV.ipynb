{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## https://github.com/fastai/fastai2/pull/82\n",
    "\n",
    "The goal of this notebook is to show how a change to `Hook` could help us write hook functions that accumulate state. \n",
    "\n",
    "In this example, we will;\n",
    "- initialize our model using a simplified LSUV (https://arxiv.org/abs/1511.06422)\n",
    "    - the simplification is that we don't pre-init with orthonormal matrices\n",
    "- save stats at each step in the LSUV loop\n",
    "    - to keep it simple, we just print the stats\n",
    "\n",
    "_The ask is_ ... can anyone help me understand how we can make this change to `Hook` using the `funcs_kwargs` decorator (instead of `can_call_with_n_positional_args`)?\n",
    "\n",
    "- `funcs_kwargs` is in fastcore/nbs/01_foundation.ipynb and\n",
    "    - `DataLoader` in fastai2/nbs/02_data.load.ipynb is a good `funcs_kwargs` example\n",
    "- `Hook` is in fastai2/nbs/15_callback.hook.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL # hack to re-instate PILLOW_VERSION\n",
    "PIL.PILLOW_VERSION = PIL.__version__\n",
    "\n",
    "from fastai2.basics import *\n",
    "from fastai2.callback.all import *\n",
    "from fastai2.vision.all import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change `Hook#hook_fn` to allow hook functions with either:\n",
    "- 3 args (model, input, output) or\n",
    "- 4 args (model, input, output, stored)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def can_call_with_n_positional_args(fn, n):\n",
    "    \"return `True` if fn can be called with n positional arguments, `False` otherwise\"\n",
    "    def _len(o): return 0 if o is None else len(o)\n",
    "    fas = inspect.getfullargspec(fn)\n",
    "    def _min(): return _len(fas.args) - _len(fas.defaults)\n",
    "    def _max(): return 99999 if fas.varargs else len(fas.args)\n",
    "    if inspect.ismethod(fn): n += 1 # add one for self\n",
    "    return n >= _min() and n <= _max()\n",
    "\n",
    "def hook_fn(self, module, input, output):\n",
    "    \"Applies `hook_func` to `module`, `input`, `output` and optionally `self`.\"\n",
    "    if self.detach:\n",
    "        input,output = to_detach(input, cpu=self.cpu, gather=self.gather),to_detach(output, cpu=self.cpu, gather=self.gather)\n",
    "    args = [module, input, output]\n",
    "    if can_call_with_n_positional_args(self.hook_func, 4): args.append(self)\n",
    "    self.stored = self.hook_func(*args)\n",
    "\n",
    "Hook.hook_fn = hook_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 256\n",
    "source = untar_data(URLs.MNIST)\n",
    "dblock = DataBlock(blocks=(ImageBlock, CategoryBlock),\n",
    "                   splitter=GrandparentSplitter(train_name='training', valid_name='testing'),\n",
    "                   get_items=get_image_files, \n",
    "                   get_y=parent_label)\n",
    "dataloaders = dblock.dataloaders(source, path=source, bs=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_layer(in_channels, out_channels, kernel_size, stride):\n",
    "    return [nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding=1), Mish()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a model with architecture similar to FitNet-MNIST (https://arxiv.org/abs/1412.6550)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential(\n",
    "    *conv_layer(3, 16, 3, 2),\n",
    "    *conv_layer(16, 16, 3, 1),\n",
    "    nn.MaxPool2d(4, 2),\n",
    "    *conv_layer(16, 16, 3, 1),\n",
    "    *conv_layer(16, 16, 3, 1),\n",
    "    nn.MaxPool2d(4, 2),\n",
    "    *conv_layer(16, 12, 3, 1),\n",
    "    *conv_layer(12, 12, 3, 1),\n",
    "    nn.AdaptiveAvgPool2d(output_size=1),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(12, 10)).cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can subclass `Hook` and easily access stored state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StoreStatsHook(Hook):\n",
    "    def __init__(self, m):\n",
    "        super().__init__(m, self.store_stats)\n",
    "        self.stored = L()\n",
    "\n",
    "    def store_stats(self, m, i, o):\n",
    "        \"save history of stats in list `hook.stored` and latest stats in `hook.stored.mean` and `hook.stored.std`\"\n",
    "        stored = self.stored\n",
    "        stored.mean, stored.std = o.data.mean().item(), o.data.std().item()\n",
    "        stored.append([stored.mean, stored.std])\n",
    "        return stored"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or we could do the same thing with a function and 3 lines less code.\n",
    "\n",
    "Note: If the function can't have a `hook` argument, we can't accumulate state with a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_stats(m, i, o, hook):\n",
    "    \"save history of stats in list `hook.stored` and latest stats in `hook.stored.mean` and `hook.stored.std`\"\n",
    "    if hook.stored is None: hook.stored = L()\n",
    "    stored = hook.stored\n",
    "    stored.mean, stored.std = o.data.mean().item(), o.data.std().item()\n",
    "    stored.append([stored.mean, stored.std])\n",
    "    return stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_lsuv(tolerance=1e-3):\n",
    "    \"re-initialize the model using simplified LSUV and return history of stats for each layer\"\n",
    "    stats = L()\n",
    "    xb, yb = dataloaders.one_batch()\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        for module in net:\n",
    "            if not isinstance(module, nn.Conv2d): continue\n",
    "            # these hooks both do the same thing\n",
    "            hook = Hook(module, store_stats)\n",
    "#             hook = StoreStatsHook(module)\n",
    "            while net(xb) is not None and abs(hook.stored.std-1) > tolerance: \n",
    "                module.weight.data /= hook.stored.std\n",
    "            hook.remove()\n",
    "            stats.append(hook.stored)\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(#3) [[-0.022715555503964424, 0.23131683468818665],[-0.039343997836112976, 0.9175119996070862],[-0.0412888340651989, 0.9990230798721313]]\n",
      "(#3) [[-0.02419188804924488, 0.34461209177970886],[-0.04715002700686455, 1.0021822452545166],[-0.04707375168800354, 0.9999953508377075]]\n",
      "(#3) [[-0.23670406639575958, 0.8159131407737732],[-0.2889198958873749, 0.9958274960517883],[-0.29010841250419617, 0.999923586845398]]\n",
      "(#3) [[-0.00022016761067789048, 0.306287556886673],[0.050328124314546585, 0.9886533617973328],[0.05116439610719681, 0.9999657869338989]]\n",
      "(#3) [[-0.10975136607885361, 0.5082138776779175],[-0.25173482298851013, 1.0027832984924316],[-0.2509334981441498, 0.9999889135360718]]\n",
      "(#3) [[-0.02601805329322815, 0.1902713179588318],[-0.1723552942276001, 0.9768433570861816],[-0.17663948237895966, 1.0000594854354858]]\n"
     ]
    }
   ],
   "source": [
    "for stats in do_lsuv(): print(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(dataloaders, net, opt_func=ranger, metrics=accuracy, loss_func=LabelSmoothingCrossEntropy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.718474</td>\n",
       "      <td>0.636540</td>\n",
       "      <td>0.967800</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.604962</td>\n",
       "      <td>0.569373</td>\n",
       "      <td>0.981700</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.559260</td>\n",
       "      <td>0.549785</td>\n",
       "      <td>0.986300</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_flat_cos(3, lr=1e-2, wd=1e-3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
